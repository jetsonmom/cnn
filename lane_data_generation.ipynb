{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jetsonmom/cnn/blob/main/lane_data_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v38fg6lxEtlL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "print(tf.__version__)\n",
        "print(cv2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# video_path = '/content/drive/MyDrive/Colab Notebooks/Image Processing/Lane Detection/1.mp4'\n",
        "video_path = '/content/drive/MyDrive/1.mp4'\n",
        "\n",
        "video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "PERSPECTIVE_IMG_W = 640\n",
        "PERSPECTIVE_IMG_H = 480\n",
        "BASE_LINE  = 340\n",
        "BASE_LINE_ROI_WIDTH = 20\n",
        "\n",
        "save_file_path = './images/original/'\n",
        "google_save_file_path = '/content/drive/MyDrive/Colab Notebooks/Image Processing/Lane Detection/images/'\n",
        "save_file_path_crop = './images/crop/'\n",
        "google_save_file_path_crop = '/content/drive/MyDrive/Colab Notebooks/Image Processing/Lane Detection/images/crop/'"
      ],
      "metadata": {
        "id": "cD0l9bF8F5kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def DeleteAllFiles(filePath):\n",
        "    if os.path.exists(filePath):\n",
        "        for file in os.scandir(filePath):\n",
        "            os.remove(file.path)\n",
        "    else:\n",
        "        os.makedirs(filePath)\n",
        "        return 'Directory not Found and make director'\n",
        "\n",
        "filePath1 = './images/original'\n",
        "print(DeleteAllFiles(filePath1))\n",
        "\n",
        "\n",
        "filePath2 = './images/crop'\n",
        "print(DeleteAllFiles(filePath2))\n",
        "\n",
        "filePath3 = './images/lane_data'\n",
        "print(DeleteAllFiles(filePath3))"
      ],
      "metadata": {
        "id": "6TBerKfzPLJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open(video_path, \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "wWq4wAFvI0dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "영상에서 이미지 만드는 코드"
      ],
      "metadata": {
        "id": "mHbGpmfOTtOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "video_path = '/content/drive/MyDrive/Colab Notebooks/Image Processing/Lane Detection/1.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "save_dir = '/content/drive/MyDrive/Colab Notebooks/Image Processing/Lane Detection/extracted_images'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # 더 이상 읽을 프레임이 없으면 종료\n",
        "\n",
        "    # 10 프레임마다 이미지 저장\n",
        "    if frame_count % 10 == 0:\n",
        "        cv2.imwrite(os.path.join(save_dir, f'frame_{frame_count}.jpg'), frame)\n",
        "        print(f'Saved frame number: {frame_count}')  # 저장된 프레임 번호 출력 (진행 상황 확인용)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "# 모든 작업 완료 후 비디오 파일 닫기\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "xVbFUuT-TsY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Image Processing/Lane Detection/images/frame_0.jpg')\n",
        "height = test_image.shape[0]\n",
        "width  = test_image.shape[1]\n",
        "\n",
        "print(height,width)\n",
        "cv2_imshow(test_image)"
      ],
      "metadata": {
        "id": "azBUc5ulSj4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 영상처리 알고리즘 함수"
      ],
      "metadata": {
        "id": "wLPd-VGKhKcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def canny_edge_detector(image):\n",
        "\n",
        "    # Convert the image color to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Reduce noise from the image\n",
        "    blur = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "    canny = cv2.Canny(blur, 40, 130)\n",
        "    return canny\n",
        "\n",
        "\n",
        "def extract_image_region_of_interest(image):\n",
        "    height = image.shape[0]\n",
        "    width  = image.shape[1]\n",
        "    crop_image = image[ BASE_LINE  - BASE_LINE_ROI_WIDTH : BASE_LINE  + BASE_LINE_ROI_WIDTH, 0: width]\n",
        "\n",
        "    return crop_image\n",
        "\n",
        "\n",
        "def OpenCV_Perspective_Calibration(image):\n",
        "\n",
        "    Source = np.float32([[0,270],[-600,480],[640,270],[640+600,480]])\n",
        "\n",
        "    Destination = np.float32([[0,0],[0,PERSPECTIVE_IMG_H], [PERSPECTIVE_IMG_W,0],[PERSPECTIVE_IMG_W,PERSPECTIVE_IMG_H]])\n",
        "    Matrix = cv2.getPerspectiveTransform(Source, Destination)\n",
        "    perspective_image = cv2.warpPerspective(image, Matrix, (PERSPECTIVE_IMG_W,PERSPECTIVE_IMG_H))\n",
        "\n",
        "    return perspective_image\n",
        "\n",
        "\n",
        "def average_slope_intercept(lines):\n",
        "    left_fit = []\n",
        "    right_fit = []\n",
        "    center_fit = []\n",
        "    slope_data =[]\n",
        "\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line.reshape(4)\n",
        "        #print x1, y1, x2, y2\n",
        "        #cv2.line(image,(x1,y1),(x2,y2),(0,255,255),1)\n",
        "        if y1 != y2 :\n",
        "            parameters = np.polyfit((y1, y2), (x1, x2), 1)\n",
        "            slope = parameters[0]\n",
        "            intercept = parameters[1]\n",
        "            slope_data.append(slope)\n",
        "\n",
        "    slope_avg = sum(slope_data) / len(slope_data)\n",
        "\n",
        "    slope_avg_degree = -math.atan(slope_avg)*180/3.14159\n",
        "\n",
        "    print('lane slope = %6.2lf'%(slope_avg_degree))\n",
        "\n",
        "    return slope_avg_degree\n",
        "\n",
        "\n",
        "def lane_image(image, lines):\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line.reshape(4)\n",
        "        cv2.line(image,(x1,y1),(x2,y2),255,2)\n",
        "    return image"
      ],
      "metadata": {
        "id": "DUcGzQTecFOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_crop = extract_image_region_of_interest(test_image)\n",
        "\n",
        "height_crop = test_image_crop.shape[0]\n",
        "width_crop  = test_image_crop.shape[1]\n",
        "cv2_imshow(test_image_crop)"
      ],
      "metadata": {
        "id": "ss-6IQ4SafNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "count=0\n",
        "\n",
        "if video_capture.isOpened() == False:\n",
        "    print(\"video file does not exit\")\n",
        "\n",
        "while(video_capture.isOpened()):\n",
        "\n",
        "    success, image =video_capture.read()   # 캡쳐된 이미지를 저장하는 함수\n",
        "\n",
        "    if success:\n",
        "        num_str = str(count).zfill(4)\n",
        "        #save_file_name = google_save_file_path + num_str + '.jpg'\n",
        "        save_file_name = save_file_path + num_str + '.jpg'\n",
        "        #save_file_crop_name = google_save_file_path_crop + 'crop_' + num_str + '.jpg'\n",
        "        save_file_crop_name = save_file_path_crop + 'crop_' + num_str + '.jpg'\n",
        "        print(save_file_name)\n",
        "        image_crop = extract_image_region_of_interest(image)\n",
        "\n",
        "        cv2.imwrite(save_file_name,image)\n",
        "        cv2.imwrite(save_file_crop_name,image_crop)\n",
        "\n",
        "        count +=1\n",
        "\n",
        "    else :\n",
        "       print(\"No stream\")\n",
        "       break\n",
        "video_capture.release()\n",
        "\n",
        "\n",
        "print(\"finish! convert video to frame\")"
      ],
      "metadata": {
        "id": "f6PL4ajLInQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_crop = extract_image_region_of_interest(test_image)\n",
        "edge_image = canny_edge_detector(test_image_crop)\n",
        "cv2_imshow(edge_image)\n",
        "print()\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "cv_dilataion = cv2.dilate(edge_image, kernel, 3)\n",
        "\n",
        "cv2_imshow(cv_dilataion)"
      ],
      "metadata": {
        "id": "DF1qkS1ngmBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "crop_image_dir = 'images/crop'\n",
        "crop_img_size = (480,640)\n",
        "\n",
        "\n",
        "input_crop_img_paths = sorted([os.path.join(crop_image_dir, fname)\n",
        "                         for fname in os.listdir(crop_image_dir)\n",
        "                         if fname.endswith('.jpg') ])\n",
        "\n",
        "no_file  = len(input_crop_img_paths)\n",
        "print(\"crop image :\",no_file)\n",
        "\n",
        "#input_img_paths[1]\n",
        "\n",
        "image_dir = 'images/original'\n",
        "img_size = (480,640)\n",
        "\n",
        "\n",
        "input_img_paths = sorted([os.path.join(image_dir, fname)\n",
        "                         for fname in os.listdir(image_dir)\n",
        "                         if fname.endswith('.jpg') ])\n",
        "\n",
        "no_file  = len(input_img_paths)\n",
        "print(\"original image :\",no_file)\n"
      ],
      "metadata": {
        "id": "BfFGRWBDancU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_line_image_empty = np.ones((height_crop,width_crop), dtype=np.uint8)\n",
        "    #cv2_imshow(cv_line_image_empty)\n",
        "cv_line_image = cv_line_image_empty.copy()\n",
        "    #cv2_imshow(cv_line_image)\n",
        "\n",
        "def line_detect(image):\n",
        "    roi_image = extract_image_region_of_interest(image)\n",
        "\n",
        "    cv_edge_roi_image = canny_edge_detector(roi_image)\n",
        "    kernel = np.ones((9,9), np.uint8)\n",
        "    cv_dilataion = cv2.dilate(cv_edge_roi_image, kernel, 3)\n",
        "\n",
        "    #cv2_imshow(cv_dilataion)\n",
        "\n",
        "    minLineLength = 10\n",
        "    maxLineGap = 5\n",
        "\n",
        "    cv_edge_roi_image_color = cv2.cvtColor(cv_edge_roi_image, cv2.COLOR_GRAY2RGB)\n",
        "    lines = cv2.HoughLinesP(cv_edge_roi_image, 2, np.pi / 180, 20,np.array([]), minLineLength,maxLineGap)\n",
        "    cv_line_image = lane_image(cv_line_image_empty, lines)\n",
        "    avg_line_slope = average_slope_intercept(lines)\n",
        "    #print(lines)\n",
        "\n",
        "\n",
        "\n",
        "    return cv_dilataion ,cv_line_image, avg_line_slope"
      ],
      "metadata": {
        "id": "f33wr28SiS5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_line_center(image,angle):\n",
        "\n",
        "\n",
        "\n",
        "    label_no, labels, stats, centroids = cv2.connectedComponentsWithStats(image)\n",
        "    line_center_pos =  np.zeros(label_no-1)\n",
        "    line_center = 0\n",
        "\n",
        "#angle = average_slope_intercept(cv_edge_roi_image_color, lines)\n",
        "    cv_line_image_color = cv2.cvtColor(cv_line_image, cv2.COLOR_GRAY2RGB)\n",
        "    for i in range(1, label_no): # 각각의 객체 정보에 들어가기 위해 반복문. 범위를 1부터 시작한 이유는 배경을 제외\n",
        "        (x, y, w, h, area) = stats[i]\n",
        "        (center_x,center_y) = centroids[i]\n",
        "        line_center_pos[i-1] = center_x\n",
        "        #print(x,y,w,h,area)\n",
        "        #print(center_x,center_y)\n",
        "        if area < 50:\n",
        "            continue\n",
        "        #cv2.rectangle(test_image_crop, (x, y, w, h), (0, 255, 255))\n",
        "        cv2.rectangle(test_image_crop, (int(center_x)-5,0, 10, 40), (0, 255, 0))\n",
        "\n",
        "\n",
        "\n",
        "    line_center_pos.sort()\n",
        "\n",
        "    if label_no == 1:\n",
        "        print('no_lane')\n",
        "    elif label_no == 2:\n",
        "        print('1 lane')\n",
        "        if(angle<0):\n",
        "            line_center = line_center_pos[0] - 306\n",
        "            cv2.line(test_image_crop, (int(line_center),0), (int(line_center),BASE_LINE_ROI_WIDTH*2),(255, 0, 0))\n",
        "        elif(angle>0):\n",
        "            line_center = line_center_pos[0] + 259\n",
        "            cv2.line(test_image_crop, (int(line_center),0), (int(line_center),BASE_LINE_ROI_WIDTH*2),(255, 0, 0))\n",
        "        cv2_imshow(test_image_crop)\n",
        "\n",
        "    elif label_no == 3:\n",
        "        print('2 lane')\n",
        "        lane_width  = line_center_pos[1]-line_center_pos[0]\n",
        "        print('lane width :', lane_width)\n",
        "\n",
        "        if (lane_width >=400):\n",
        "            if(angle<0):\n",
        "                line_center = line_center_pos[1] - 306\n",
        "                cv2.line(test_image_crop, (int(line_center),0), (int(line_center),BASE_LINE_ROI_WIDTH*2),(255, 0, 0))\n",
        "            elif(angle>0):\n",
        "                line_center = line_center_pos[0] + 259\n",
        "                cv2.line(test_image_crop, (int(line_center),0), (int(line_center),BASE_LINE_ROI_WIDTH*2),(255, 0, 0))\n",
        "\n",
        "\n",
        "        elif (lane_width <400) & (lane_width >=230):\n",
        "            if(angle<0):\n",
        "                line_center = line_center_pos[0]\n",
        "                cv2.line(test_image_crop, (int(line_center),0), (int(line_center),BASE_LINE_ROI_WIDTH*2),(255, 0, 0))\n",
        "            elif(angle>0):\n",
        "                line_center = line_center_pos[1]\n",
        "                cv2.line(test_image_crop, (int(line_center),0), (int(line_center),BASE_LINE_ROI_WIDTH*2),(255, 0, 0))\n",
        "\n",
        "\n",
        "\n",
        "        elif (lane_width < 230):\n",
        "            line_center = line_center_pos[1]\n",
        "            cv2.line(test_image_crop, (int(line_center),0), (int(line_center),BASE_LINE_ROI_WIDTH*2),(255, 0, 0))\n",
        "\n",
        "\n",
        "        cv2_imshow(test_image_crop)\n",
        "    elif label_no == 4:\n",
        "        print('3 lanes')\n",
        "        line_center = line_center_pos[1]\n",
        "        cv2.line(test_image_crop, (int(line_center),0), (int(line_center),BASE_LINE_ROI_WIDTH*2),(255, 0, 0))\n",
        "\n",
        "        cv2_imshow(test_image_crop)\n",
        "    else :\n",
        "        print('too many lane')\n",
        "\n",
        "    return line_center"
      ],
      "metadata": {
        "id": "3VtXuzck9WPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 설명\n",
        "i = 100:\n",
        "i 변수에 100이라는 값을 할당합니다. 이는 일반적으로 인덱스나 순번을 나타내며, 배열이나 리스트에서 특정 위치의 요소를 참조할 때 사용됩니다.\n",
        "print(input_img_paths[i]):\n",
        "input_img_paths 리스트에서 인덱스 100에 해당하는 요소의 값을 출력합니다. 이 값은 이미지 파일의 경로일 가능성이 높습니다.\n",
        "test_image = cv2.imread(input_img_paths[i]):\n",
        "OpenCV의 cv2.imread() 함수를 사용하여 input_img_paths 리스트의 100번째 요소(이미지 파일 경로)를 읽어들여 test_image 변수에 저장합니다.\n",
        "test_image_crop = cv2.imread(input_crop_img_paths[i]):\n",
        "input_crop_img_paths 리스트의 100번째 요소를 사용하여 특정 부분이 자른(cropped) 이미지를 읽어들입니다.\n",
        "lane_dilation_img, cv_line_image, line_angle = line_detect(test_image):\n",
        "line_detect 함수를 호출하여 test_image에서 차선을 감지합니다. 이 함수는 세 개의 결과를 반환합니다:\n",
        "lane_dilation_img: 차선 감지 후 처리된 이미지(확대된 차선 등을 포함할 수 있음).\n",
        "cv_line_image: 차선이 표시된 이미지.\n",
        "line_angle: 감지된 차선의 각도.\n",
        "line_center = cal_line_center(lane_dilation_img, line_angle):\n",
        "cal_line_center 함수를 사용하여 lane_dilation_img 이미지와 line_angle을 바탕으로 차선의 중심을 계산합니다.\n",
        "결과 메시지 출력:\n",
        "\"images/original/0100.jpg\"는 처리된 이미지의 경로를 나타냅니다.\n",
        "\"lane slope = 35.01\"는 감지된 차선의 기울기를 나타냅니다.\n",
        "\"too many lane\"은 감지된 차선이 너무 많음을 나타내는 메시지입니다."
      ],
      "metadata": {
        "id": "uF85zhQDWIt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 100\n",
        "print(input_img_paths[i])\n",
        "test_image = cv2.imread(input_img_paths[i])\n",
        "test_image_crop = cv2.imread(input_crop_img_paths[i])\n",
        "lane_dilation_img, cv_line_image, line_angle  = line_detect(test_image)\n",
        "line_center = cal_line_center(lane_dilation_img, line_angle)"
      ],
      "metadata": {
        "id": "q6MUu4SePVRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(len(input_img_paths)):\n",
        "\n",
        "result_save_file_path = './images/lane_data/'\n",
        "google_result_save_file_path = '/content/drive/MyDrive/Colab Notebooks/Image Processing/Lane Detection/images/lane_center_data/'\n",
        "\n",
        "for i in range(1400):\n",
        "    print(input_img_paths[i])\n",
        "\n",
        "    num_str = str(i).zfill(4)\n",
        "    save_file_name = google_result_save_file_path + 'lane_center_'+ num_str + '.txt'\n",
        "    #print(save_file_name)\n",
        "    line_center = 10.1\n",
        "    f = open(save_file_name,'w')\n",
        "    test_image = cv2.imread(input_img_paths[i])\n",
        "    test_image_crop = cv2.imread(input_crop_img_paths[i])\n",
        "    lane_dilation_img, cv_line_image, line_angle  = line_detect(test_image)\n",
        "    line_center = cal_line_center(lane_dilation_img, line_angle)\n",
        "    data = '%4.1f'%line_center\n",
        "    f.write(data)\n",
        "    f.close\n",
        "\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "Jt7iF6GsEyJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 데이터 중에서 1400까지만 할 것\n",
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Nyqck1NzSfUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(10):\n",
        "    num_str1 = str(j).zfill(4)\n",
        "\n",
        "    #num_str1.rjust(4,'0')\n",
        "    print(num_str1)"
      ],
      "metadata": {
        "id": "cpueRHlIHUu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TBswCZWu5Gcz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}